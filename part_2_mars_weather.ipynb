{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 12 Challenge\n",
    "## Deliverable 2: Scrape and Analyze Mars Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import requests\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify the path\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Visit the Website\n",
    "\n",
    "Use automated browsing to visit the [Mars Temperature Data Site](https://static.bc-edx.com/data/web/mars_facts/temperature.html). Inspect the page to identify which elements to scrape.\n",
    "\n",
    "   > **Hint** To identify which elements to scrape, you might want to inspect the page by using Chrome DevTools to discover whether the table contains usable classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the Mars Temperature Data Site: \n",
    "url = 'https://static.bc-edx.com/data/web/mars_facts/temperature.html'\n",
    "response = requests.get(url)\n",
    "browser.visit(url)\n",
    "html = requests.get(url).text\n",
    "article_list_soup = soup(html, 'html.parser')\n",
    "html_content = response.content\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Scrape the Table\n",
    "\n",
    "Create a Beautiful Soup object and use it to scrape the data in the HTML table.\n",
    "\n",
    "Note that this can also be achieved by using the Pandas `read_html` function. However, use Beautiful Soup here to continue sharpening your web scraping skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Mars Temperature Data</title>\n",
      "Mars Temperature Data\n"
     ]
    }
   ],
   "source": [
    "# Extract data as test\n",
    "title = soup.title\n",
    "print(title)\n",
    "print(title.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "css/bootstrap.min.5.2.2.css\n",
      "css/temp.css\n"
     ]
    }
   ],
   "source": [
    "Links = soup.find_all('link',href=True)\n",
    "for link in Links:\n",
    "    print(link['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a little more practice\n",
    "\n",
    "Data_Rows = soup.find_all('table',data_row=True)\n",
    "for data_row in Data_Rows:\n",
    "    print(table[data_row])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_rows' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/y2/zm53gsnx68x_cmcfjm18bhl40000gn/T/ipykernel_15162/2833183011.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mData_Rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'table'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_row\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msoup_data_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_rows' is not defined"
     ]
    }
   ],
   "source": [
    "# find the table rows using the 'find_all' method (To be revised)\n",
    "soup_data_rows = soup.find_all('tr')\n",
    "print(data_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping rows_data: name 'soup_rows' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Create a Beautiful Soup Object\n",
    "\n",
    "try:\n",
    "    data_rows_soup = soup_rows.find('tbody', class_='tr')\n",
    "    rows_data = soup_data.find_all('tr', class_='data_row')\n",
    "except Exception as e:\n",
    "    print(f'Error scraping rows_data: {e}')\n",
    "    browser.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the table element containing the data\n",
    "table = soup.find('table', {'class': 'data-table'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f88a61b9d90>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/b534ba0f8ab90febd8b4d6a2f7bffa89\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f88a152f1d0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/b534ba0f8ab90febd8b4d6a2f7bffa89\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f88a61b92d0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/b534ba0f8ab90febd8b4d6a2f7bffa89\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f88a61c0890>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/b534ba0f8ab90febd8b4d6a2f7bffa89\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f88a61c0b10>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/b534ba0f8ab90febd8b4d6a2f7bffa89\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f88a61c0bd0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/b534ba0f8ab90febd8b4d6a2f7bffa89\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f88a61c0050>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/b534ba0f8ab90febd8b4d6a2f7bffa89\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f88a61c0150>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/b534ba0f8ab90febd8b4d6a2f7bffa89\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f88a610c350>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/b534ba0f8ab90febd8b4d6a2f7bffa89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping rows_data: 'str' object has no attribute 'descendants'\n"
     ]
    }
   ],
   "source": [
    "# Extract all rows of data\n",
    "try:\n",
    "    rows_of_data_soup = soup.find_all('table', class_='table')\n",
    "    rows_data_soup = soup.find_all('tbody', class_='data_row')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f'Error scraping rows_data: {e}')\n",
    "    browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rows_data_soup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/y2/zm53gsnx68x_cmcfjm18bhl40000gn/T/ipykernel_15162/2413950766.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrows_data_soup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'rows_data_soup' is not defined"
     ]
    }
   ],
   "source": [
    "rows_data_soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Store the Data\n",
    "\n",
    "Assemble the scraped data into a Pandas DataFrame. The columns should have the same headings as the table on the website. Hereâ€™s an explanation of the column headings:\n",
    "\n",
    "* `id`: the identification number of a single transmission from the Curiosity rover\n",
    "* `terrestrial_date`: the date on Earth\n",
    "* `sol`: the number of elapsed sols (Martian days) since Curiosity landed on Mars\n",
    "* `ls`: the solar longitude\n",
    "* `month`: the Martian month\n",
    "* `min_temp`: the minimum temperature, in Celsius, of a single Martian day (sol)\n",
    "* `pressure`: The atmospheric pressure at Curiosity's location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list\n",
    "\n",
    "# Loop through the scraped data to create a list of rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas DataFrame by using the list of rows and a list of the column names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm DataFrame was created successfully\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Prepare Data for Analysis\n",
    "\n",
    "Examine the data types that are currently associated with each column. If necessary, cast (or convert) the data to the appropriate `datetime`, `int`, or `float` data types.\n",
    "\n",
    "  > **Hint** You can use the Pandas `astype` and `to_datetime` methods to accomplish this task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine data type of each column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change data types for data analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm type changes were successful by examining data types again\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Analyze the Data\n",
    "\n",
    "Analyze your dataset by using Pandas functions to answer the following questions:\n",
    "\n",
    "1. How many months exist on Mars?\n",
    "2. How many Martian (and not Earth) days worth of data exist in the scraped dataset?\n",
    "3. What are the coldest and the warmest months on Mars (at the location of Curiosity)? To answer this question:\n",
    "    * Find the average the minimum daily temperature for all of the months.\n",
    "    * Plot the results as a bar chart.\n",
    "4. Which months have the lowest and the highest atmospheric pressure on Mars? To answer this question:\n",
    "    * Find the average the daily atmospheric pressure of all the months.\n",
    "    * Plot the results as a bar chart.\n",
    "5. About how many terrestrial (Earth) days exist in a Martian year? To answer this question:\n",
    "    * Consider how many days elapse on Earth in the time that Mars circles the Sun once.\n",
    "    * Visually estimate the result by plotting the daily minimum temperature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. How many months are there on Mars?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. How many Martian days' worth of data are there?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. What is the average low temperature by month?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the average temperature by month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the coldest and hottest months in Curiosity's location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Average pressure by Martian month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the average pressure by month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. How many terrestrial (earth) days are there in a Martian year?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, the third month has the coldest minimum temperature on Mars, and the eighth month is the warmest. But it is always very cold there in human terms!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atmospheric pressure is, on average, lowest in the sixth month and highest in the ninth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distance from peak to peak is roughly 1425-750, or 675 days. A year on Mars appears to be about 675 days from the plot. Internet search confirms that a Mars year is equivalent to 687 earth days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Save the Data\n",
    "\n",
    "Export the DataFrame to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the data to a CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
